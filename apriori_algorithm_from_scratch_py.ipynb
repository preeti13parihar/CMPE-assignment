{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "apriori_algorithm_from_scratch.py",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Apriori algorithm developed and used on a sample dataset"
      ],
      "metadata": {
        "id": "oFRZJC4oP1o2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u5RjLuDvN6Yg"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from itertools import combinations\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transactions = {\n",
        "#     1: [\"a\", \"c\", \"d\"],\n",
        "#     2: [\"b\", \"c\", \"e\"],\n",
        "#     3: [\"a\", \"b\", \"c\", \"e\"],\n",
        "#     5: [\"b\", \"e\"],\n",
        "#     6: [\"a\", \"c\", \"e\"]\n",
        "# }\n",
        "\n"
      ],
      "metadata": {
        "id": "qKJUFdA-P-qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = {\n",
        "    1: [\"1\", \"3\", \"4\"],\n",
        "    2: [\"2\", \"3\", \"5\"],\n",
        "    3: [\"1\", \"2\", \"3\", \"5\"],\n",
        "    5: [\"2\", \"5\"],\n",
        "    6: [\"1\", \"3\", \"5\"]\n",
        "}"
      ],
      "metadata": {
        "id": "uDqKP_V_N_nw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_support_count = 2\n",
        "min_confidence_value = 0.6"
      ],
      "metadata": {
        "id": "G8ZB-4pHOGKH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# apriori pruning concept"
      ],
      "metadata": {
        "id": "_zJhfR6BQEqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _pruning(current, previous, size):\n",
        "    final_keys = []\n",
        "    previous = [tuple(i) for i in previous]\n",
        "    for key in current:\n",
        "        FLAG = False\n",
        "        current_comb = list(combinations(key, size))\n",
        "        for i in current_comb:\n",
        "            if i in previous or i[::-1] in previous:\n",
        "                FLAG = True\n",
        "            else:\n",
        "                FLAG = False\n",
        "                break\n",
        "\n",
        "        if FLAG:\n",
        "            final_keys.append(key)\n",
        "\n",
        "    return final_keys"
      ],
      "metadata": {
        "id": "4aNDx6f7OOtn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def support_value(itemset_keys_, transactions):\n",
        "    itemset = {key: 0 for key in itemset_keys_}\n",
        "\n",
        "    for keys in itemset_keys_:\n",
        "        for val in transactions.values():\n",
        "            if set(keys) & set(val) == set(keys):\n",
        "                itemset[keys] += 1\n",
        "    return itemset"
      ],
      "metadata": {
        "id": "Xe1AWM9iOV_f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating frequent itemset"
      ],
      "metadata": {
        "id": "Oi6eihlNQLY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frequent_itemset(size=None, transactions=None, itemset=None):\n",
        "    if size == 1:\n",
        "        itemset = Counter()\n",
        "\n",
        "        for val in transactions.values():\n",
        "            itemset.update(val)\n",
        "\n",
        "    else:\n",
        "\n",
        "        prev_itemset_keys = list(itemset.keys())\n",
        "        prev_itemset = itemset.copy()\n",
        "\n",
        "        valid_keys = list(set(itemset.keys()))\n",
        "        # flatten list of tuple -> keys: [(), ()] -> []\n",
        "        # useful for running a combination of all the chosen features\n",
        "        l = []\n",
        "        for row in valid_keys:\n",
        "            l.extend(row)\n",
        "\n",
        "        valid_keys = set(l)\n",
        "\n",
        "        # candidate itemset keys\n",
        "        itemset_keys_ = list(combinations(valid_keys, size))\n",
        "\n",
        "        # Apriori algorithm is based on theconcept that a subset\n",
        "        # of a frequent itemset must also be a frequent itemset\n",
        "        # so we are pruning away those features whose subset are not present\n",
        "        # in the previous frequent itemset\n",
        "        if size >= 2:\n",
        "            itemset_keys_ = _pruning(\n",
        "                itemset_keys_, prev_itemset_keys, size - 1)\n",
        "\n",
        "        # finding support value for each of the selected itemset feature combination\n",
        "        itemset = support_value(itemset_keys_, transactions)\n",
        "\n",
        "        # defaulting back to th previous frequent itemset if\n",
        "        # the iteration doesn't find any itemset which has the theshold required\n",
        "        if itemset == {}:\n",
        "            itemset = prev_itemset\n",
        "\n",
        "    # getting frequent itemset from itemset\n",
        "    # Frequent Itemset is an itemset whose support\n",
        "    # value is greater than a threshold value(support).\n",
        "\n",
        "    frequent_itemset = {}\n",
        "    for key, val in itemset.items():\n",
        "        if val >= min_support_count:\n",
        "            frequent_itemset[key] = val\n",
        "\n",
        "    return frequent_itemset\n",
        "\n"
      ],
      "metadata": {
        "id": "VXeTUK11OaKx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finding_subsets(frequent_set):\n",
        "    item_list = []\n",
        "    size = len(list(frequent_set.keys())[0])\n",
        "    for key in frequent_set.keys():\n",
        "        subsets = []\n",
        "        for i in range(1, size):\n",
        "            subsets.append(list(combinations(key, i)))\n",
        "\n",
        "        subsets = list(np.array(subsets).flatten())\n",
        "        subsets.insert(0, key)\n",
        "        item_list.append(subsets)\n",
        "\n",
        "    return item_list\n",
        "\n",
        "\n",
        "def finding_rules(itemset_sub):\n",
        "    print(\"Antecedents -->  Consequents --- Confidence\")\n",
        "    for i in range(1, len(itemset_sub)):\n",
        "\n",
        "        # passing as list as we have designed support_value function as\n",
        "        # a function that takes an iteratable list of itemsets\n",
        "        x = support_value([itemset_sub[0], ], transactions)\n",
        "        y = support_value([itemset_sub[i], ], transactions)\n",
        "        confidence = list(x.values())[0] / list(y.values())[0]\n",
        "        if confidence >= min_confidence_value:\n",
        "            print(\n",
        "                f\"{itemset_sub[i]} --> {itemset_sub[0]} --- {round(confidence, 2)}\")"
      ],
      "metadata": {
        "id": "8vS9EihnOl4p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "    ITEMS\n",
        "    1: Banana\n",
        "    2: Eggs\n",
        "    3: Milk\n",
        "    4: Tea\n",
        "    5: Bread\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRDZ7983PRH5",
        "outputId": "6dceb1c8-2ca3-4233-bd41-d851bea34231"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    ITEMS\n",
            "    1: Banana\n",
            "    2: Eggs\n",
            "    3: Milk\n",
            "    4: Tea\n",
            "    5: Bread\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# frequent_itemsets"
      ],
      "metadata": {
        "id": "T78hX7pGQWH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = {}\n",
        "\n",
        "for i in range(1, 5):\n",
        "    f = get_frequent_itemset(size=i, transactions=transactions,\n",
        "                             itemset=f)\n",
        "\n",
        "# frequent_itemsets\n",
        "\n",
        "print(\"Frequent Itemsets...\")\n",
        "for key, val in f.items():\n",
        "    print(f\"Itemset: {key}, support value: {val}\")\n",
        "\n",
        "\n",
        "subset = finding_subsets(f)\n",
        "\n",
        "for i in subset:\n",
        "    print(f\"Rules for itemset - {i[0]}\")\n",
        "    finding_rules(i)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGmKfZ52PWN4",
        "outputId": "9261a854-7cc9-4a0c-841e-80ad6f4f876d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets...\n",
            "Itemset: ('2', '3', '5'), support value: 2\n",
            "Itemset: ('1', '3', '5'), support value: 2\n",
            "Rules for itemset - ('2', '3', '5')\n",
            "Antecedents -->  Consequents --- Confidence\n",
            "('2',) --> ('2', '3', '5') --- 0.67\n",
            "('2', '3') --> ('2', '3', '5') --- 1.0\n",
            "('2', '5') --> ('2', '3', '5') --- 0.67\n",
            "('3', '5') --> ('2', '3', '5') --- 0.67\n",
            "\n",
            "Rules for itemset - ('1', '3', '5')\n",
            "Antecedents -->  Consequents --- Confidence\n",
            "('1',) --> ('1', '3', '5') --- 0.67\n",
            "('1', '3') --> ('1', '3', '5') --- 0.67\n",
            "('1', '5') --> ('1', '3', '5') --- 1.0\n",
            "('3', '5') --> ('1', '3', '5') --- 0.67\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GgsxYQWaPaQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}